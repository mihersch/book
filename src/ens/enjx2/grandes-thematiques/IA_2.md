<style>
.button {
  background-color: white;
  border: 1px solid;
  border-color: black;
  font-family:"Lato",sans-serif;
  font-weight:350;
  color: black!important;
  padding: 10px 10px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 16px;
  margin: 4px 2px;
  cursor: pointer;
}
.button:hover {
  text-decoration:none;
  background-color: black; 
  color: white!important;
}
.round-button {
    display:block;
    width:100px;
    height:100px;
    line-height:17px;
    border:0px ;
    border-radius: 50%;
    color:#6069db;
    text-align:center;
    text-decoration:none;
    display: table-cell;
    vertical-align: middle;
    background: #6069db;
    box-shadow: 0 0 0px gray;
    font-size:14px;
    font-weight:bold;
    }

</style>

<div align="right"> 
    <a href="http://files.modulo-info.ch/enjeux-sociaux/ia-automatisation/IA-AutomatisationP2.pdf" class="round-button">
         <font color=white id="demo">Cliquer ici pour <br>dossier</font>
    </a>
</div>

# IA et enjeux de l'automatisation, partie 2

<br>

Cette seconde partie du dossier permet d‚Äôapprofondir quelques questions relatives √† l‚ÄôIA et √†
l‚Äôautomatisation. Le travail des √™tres humains est-il en train de dispara√Ætre face √† l‚Äôautomatisation
de certaines t√¢ches? Quels sont les domaines dans lesquels l‚ÄôIA est particuli√®rement efficace?
√Ä quoi faut-il faire attention? Comment ses usages et applications peuvent-ils √™tre r√©gul√©s?

## Objectifs

-   Comprendre comment l'IA et l'automatisation impacte et transforme le
    march√© du travail

-   Explorer les forces et les risques relatifs √† l'IA

-   √âtudier le th√®me de la conduite autonome √† travers le prisme de l'IA

## Enjeux

Gr√¢ce aux r√©centes perc√©es de l'apprentissage automatique, l'IA franchit
aujourd'hui une nouvelle √©tape, comme en t√©moigne l'augmentation
consid√©rable (AI Report 2022, HAI Stanford) des investissements depuis
2013. Des domaines aussi divers que la sant√©, l'√©ducation, mais aussi le
commerce, l'industrie et la recherche int√®grent ces technologies et se
transforment. Ce retour en force de l'IA implique un questionnement
accru sur ses effets. Il est notamment question de d√©l√©gation du travail
et des cons√©quences sur l'emploi, de transparence, de protection de la
vie priv√©e et de cadre juridique.

### üéõ D√©l√©gation

L'automatisation consiste √† d√©l√©guer de mani√®re syst√©matique une t√¢che
ou une prise de d√©cision √† une machine. Il existe toujours plusieurs
mani√®res d'envisager la d√©l√©gation d'une t√¢che, que ce soit en termes de
faisabilit√© ou de d√©sirabilit√©. Dans les deux cas, ses effets sur l'√™tre
humain et la soci√©t√© face aux nouvelles technologies doivent √™tre
consid√©r√©s.

Les questions de d√©l√©gation du travail ne sont pas propres √† l'IA. Elles
se posaient d√©j√† √† l'aube de la r√©volution industrielle. Au d√©but du
XIXe si√®cle, le mouvement des luddites en Grande-Bretagne organisait la
destruction de nouvelles machines, accus√©es d'augmenter le ch√¥mage. Mais
les luttes sociales face aux nouvelles technologies furent rapidement
vaincues par l'industrialisation et la m√©canisation du travail, qui
suivirent leur cours jusqu'√† nos jours.

Aujourd'hui, les technologies de l'IA r√©actualisent et prolongent cette
dynamique. En plus des possibilit√©s de d√©l√©guer des fonctions m√©caniques
aux machines, il est d√©sormais possible de d√©l√©guer certaines fonctions
cognitives.

![private_investments_in_AI](media/image_1_1.jpg)

Investissements mondiaux priv√©s dans le domaine de l'IA entre 2013 et
2021, en milliards de dollars.

### ü¶æ Le travail au d√©fi de l'IA

En 2013, une √©tude men√©e par des chercheurs de l'Universit√© d'Oxford
conclut que 47% des emplois sont menac√©s par les avanc√©es dans le
domaine de l'apprentissage automatique. Ces r√©sultats alarmants sont
rapidement remis en cause par des erreurs m√©thodologiques. De plus, les
nouveaux emplois n√©cessaire au d√©veloppement et au suivi de l'IA ne sont
pas mentionn√©s. Cette √©tude nous am√®ne n√©anmoins √† r√©fl√©chir √† l'impact
de l'automatisation et de l'IA sur les emplois, dans un contexte o√π la
technologie transforme effectivement le march√© du travail.

Comme expliqu√© par l'√©conomiste David H. Autor (MIT) en 2015, le
discours du remplacement du travail de l'√™tre humain par la machine
ainsi que les craintes qui en d√©coulent ne sont pas r√©cents. Les donn√©es
historiques montrent n√©anmoins que le ph√©nom√®ne ne se v√©rifie pas
empiriquement. Si l'automatisation de nombreux secteurs a bien eu lieu
au cours du XXe si√®cle et continue aujourd'hui encore, l'√©volution des
taux de ch√¥mage de diff√©rents pays ne refl√®te pas une baisse drastique
de l'emploi. On observe plut√¥t une transformation du march√© du travail,
avec un renversement de la distribution de l'emploi du secteur primaire
vers le secteur tertiaire. Une analyse plus fine des impacts de l'IA sur
le travail et l'√©conomie s'impose donc.

Dans son livre En attendant les robots (Seuil, 2019), le sociologue
Antonio Casilli d√©construit la croyance du remplacement du travail de
l'√™tre humain par les machines et les IA. Il constate, lui aussi, une
transformation du march√© du travail plut√¥t qu'une disparition des
emplois. Avec l'arriv√©e des nouvelles technologies de l'information et
de la communication, une tendance √† la polarisation se dessine : d'un
c√¥t√©, une forte demande pour les m√©tiers hautement sp√©cialis√©s est
constat√©e; de l'autre, un besoin croissant de main d'≈ìuvre peu qualifi√©e
pour effectuer des t√¢ches r√©p√©titives et standardis√©es, essentielles au
bon fonctionnement des syst√®mes automatis√©s. Cet seconde cat√©gorie
d'emplois, peu qualifi√©s mais indispensables √† l'entra√Ænement des IA,
constitue ce que l'on appelle le digital labour.

La question n'est donc pas de savoir si l'IA remplacera un jour les
travailleurs, mais plut√¥t de r√©fl√©chir √† la pertinence d'int√©grer les
technologies algorithmiques dans diff√©rentes situations et dans quelles
proportions. Elle nous am√®ne √©galement √† envisager des solutions
permettant de g√©rer les transformations socio-√©conomiques qui r√©sultent
de l'automatisation de certaines t√¢ches.

Afin que les avantages de l'IA profitent au plus grand nombre, les
syst√®mes √©conomiques et politiques doivent s'adapter aux changements
induits par l'automatisation. La redistribution des t√¢ches, et donc de
la productivit√© engendr√©e par l'automatisation modifie la redistribution
du travail ainsi que du gain de productivit√© et du capital. Les
entreprises vont-elles continuer √† profiter de l'automatisation du
travail? Dans quelles proportions? Faut-il envisager de taxer les gains
engendr√©s par les machines et les syst√®mes d'IA afin d'assurer les
mod√®les sociaux en place (Assurance ch√¥mage, AVS, etc.)? Ces questions
centrales peinent √† s'imposer dans le d√©bat public, mais elles devront
√™tre consid√©r√©es t√¥t ou tard.

### üß¨ Domaines de pr√©dilection

L'efficacit√© d'un mod√®le pr√©dictif d'IA est li√©e √† la nature des donn√©es
qu'il traite. Lorsqu'il s'agit d'informations stables et objectives,
comme c'est le cas pour les pixels d'une image repr√©sentant une forme,
les techniques d'apprentissage automatique fonctionnent relativement
bien et offre des r√©sultats satisfaisants. Les possibilit√©s
d'automatisation de l'IA offrent alors des avantages multiples, par
exemple pour la recherche scientifique et m√©dicale.

Les algorithmes et l'IA ont d√©j√† fait leurs preuves pour d√©tecter
certains cancers plus rapidement que les sp√©cialistes. En 2020, la
soci√©t√© DeepMind (Alphabet) a r√©volutionn√© la bio-informatique en
proposant un mod√®le de pr√©diction de la structure des prot√©ines,
permettant d'acc√©l√©rer fortement la recherche pour l'√©laboration de
nouveaux vaccins.

Dans les deux cas, l'apprentissage automatique est utilis√© pour
effectuer une t√¢che pr√©cise et compartiment√©e, qui s'inscrit dans un
contexte plus large. Le travail des chercheurs et des scientifiques
demeure toutefois indispensable pour comprendre, communiquer les
r√©sultats et coordonner l'ensemble d'un projet.

### üë¶üèæüëß L'IA appliqu√©e au monde social

D√©l√©guer des prises de d√©cision s'av√®rent plus risqu√© dans d'autres
domaines. En effet, de nombreux biais racistes et sexistes, pr√©sents
dans les donn√©es utilis√©es pour entra√Æner des mod√®les pr√©dictifs, ont
√©t√© reproduits et amplifi√©s lors de processus de recrutement
automatis√©s, dans la suggestion de vid√©os sur Facebook ou m√™me lors de
prises de d√©cision par le syst√®me judiciaire am√©ricain. Lorsque les
donn√©es fournies √† une IA sont subjectives et non-repr√©sentatives, les
biais qu'elles contiennent se retrouvent dans les pr√©dictions √©tablies.
La tendance qui consiste √† vouloir r√©guler le monde social √† partir des
donn√©es qu'il produit est appel√©e gouvernementalit√© algorithmique.

Le physicien, familier des sciences sociales, Pablo Jensen a d√©montr√©
que cette ¬´mise en √©quation de la soci√©t√©¬ª n'est que rarement efficace.
Il explique que la complexit√© du monde social est difficilement
r√©ductible √† un ensemble de donn√©es, aussi nombreuses soient-elles.
Cette logique s'applique aussi au niveau individuel. L'utilisation des
donn√©es personnelles et biom√©triques dans le cadre de prises de d√©cision
automatis√©es n'est pas toujours adapt√©e ni souhaitable. Profiler une
personne √† partir de ses traces num√©riques implique forc√©ment que
certaines informations soient prises en compte et d'autres non.

Pourtant, faute d'une r√©flexion plus large sur les diff√©rentes
possibilit√©s d'arbitrer des prises de d√©cision complexes, l'IA et ses
algorithmes sont bien souvent pr√©sent√©s comme une solution efficace pour
pallier la subjectivit√© humaine. Face aux cas de biais algorithmiques,
la rh√©torique dominante est de les r√©soudre √† tout prix, en r√©coltant
plus de donn√©es sur les groupes sous-repr√©sent√©s. Or, il est na√Øf de
penser que les in√©galit√©s pr√©sentes dans la soci√©t√© pourraient √™tre
r√©duites par le traitement automatique des donn√©es qui en √©manent.

L'utilisation des logiciels de reconnaissance faciale illustrent cette
probl√©matique. Plusieurs cas de discriminations raciales et/ou sexistes
caus√©es par des algorithmes mal entra√Æn√©s ont √©t√© r√©v√©l√©s, notamment
dans le documentaire Coded Bias (Netflix, 2020). L'ing√©nieure et
chercheuse du MIT Joy Buolamwini y explique avoir elle-m√™me √©t√© victime
de ces biais. Elle travaille d√©sormais √† l'am√©lioration de la
reconnaissance de tous les visages. Pourtant, tout comme le discours
dominant le domaine de l'IA, l'usage m√™me de ces technologies n'est pas
remis en question.

Plusieurs arguments invitent toutefois √† questionner l'usage de la
reconnaissance faciale plut√¥t que de corriger les biais qu'elle
amplifie. D'abord, cette technologie permet une surveillance accrue des
individus. Elle est notamment utilis√©e par les institutions judiciaire
et polici√®re, en Chine, aux √âtats-Unis mais aussi en Europe. Les
minorit√©s visibles, d√©j√† plus souvent concern√©es par les contr√¥les de
police, n'ont donc pas int√©r√™t √† vouloir √† tout prix √™tre reconnues par
l'IA. Ensuite, la mise en place de syst√®mes de reconnaissance faciale
implique l'automatisation de la collecte de donn√©es personnelles √†
grande √©chelle. Toute personne passant devant une cam√©ra est trac√©e par
d√©faut, ce qui porte atteinte au droit √† la vie priv√©e. Se pose
finalement la question de la gestion des donn√©e. Comment sont-elles
g√©r√©es et √† quelles autres donn√©e sont-elles associ√©es? O√π sont-elles
stock√©es? Qui peut y acc√©der? Que se passe-t-il en cas de cyberattaque?

La question de l'application de l'IA au monde social est donc complexe
et particuli√®rement sensible. Pour profiter des avantages de ces
nouvelles technologies tout en limitant les risques qu'elles comportent,
diff√©rentes solutions de r√©gulation existent.

```{admonition} La main mise d'Alphabet
:class: hint

Dans l'histoire r√©cente de l'IA, l'entreprise Alphabet, maison m√®re de
Google, se d√©marque particuli√®rement par la diversit√© de ses
engagements. Ses produits phares, tels que son moteur de recherche et
son traducteur automatique, facilitent nos usages num√©riques au
quotidien gr√¢ce √† l'apprentissage automatique.

L'entreprise investit √©galement dans divers domaines de recherche¬†:
conduite autonome, sant√©, syst√®me de reconnaissance de formes et de
sons, ainsi que le d√©veloppement de robots.

Finalement, la puissance √©conomique d'Alphabet lui permet d'acqu√©rir les
entreprises dans lesquelles r√©sident un fort potentiel pour la recherche
en IA. En 2014, elle rach√®te la firme britannique DeepMind qui mettra au
point l'embl√©matique programme AlphaGo, ainsi que AlphaFold, logiciel
capable de pr√©dire la structure de certaines prot√©ines gr√¢ce √† des
r√©seaux de neurones artificiels. Alphabet a ainsi rachet√© des dizaines
d'entreprises afin de rester √† la pointe de la recherche dans le domaine
de l'IA.
```

### ‚öñ R√©guler l'IA

√Ä la suite des diverses controverses engendr√©es par des IA, de grandes
entreprises comme Google, Microsoft ou IBM ont mis en place des comit√©s
d'√©thique. Plusieurs projets ont √©t√© suspendus en raison du risque de
perp√©tuer des pratiques discriminatoires. Il s'agit dans ce cas d'une
forme de gouvernance interne, non-contraignante, appliqu√©e au bon
vouloir des entreprises.

Du c√¥t√© de la soci√©t√© civile, des mouvements citoyens se sont
constitu√©s, √† l'image de la campagne contre la reconnaissance faciale
lanc√©e par Amnesty International en 2020 et de l'ONG AlgorithmWatch.
Cette organisation se focalise particuli√®rement sur les risques li√©s aux
prises de d√©cisions bas√©es sur des algorithmes. En plus des articles
permettant d'expliquer les enjeux relatifs aux prises de d√©cisions
automatis√©es, elle propose quelques r√®gles de bonnes pratiques pour
collecter, analyser et interpr√©ter les donn√©es, tout en privil√©giant les
int√©r√™ts humains et sociaux.

Les revendications de ces organisations quant √† la protection de la vie
priv√©e s'inscrivent dans un mouvement de d√©fiance politique, oppos√© √†
l'adoption de nouveaux modes de surveillance par les gouvernements. Si
les d√©mocraties tentent de faire preuve de bonne volont√© et r√©gulent les
applications de l'IA dans l'int√©r√™t de leurs citoyens, les r√©gimes
autoritaires n'h√©sitent pas √† utiliser les donn√©es qu'elles poss√®dent
pour contr√¥ler les masses. Dans un contexte politique mondial incertain,
il est n√©cessaire de r√©fl√©chir aux risques des dispositifs de
surveillance, en cas de changement de r√©gime politique par exemple.

La volont√© de r√©guler l'IA varient selon les r√©gions du monde et les
syst√®mes politiques en place. Aux √âtats-Unis, actuel leader mondial dans
le domaine, seuls quatre √âtats ont adopt√© une forme de r√©gulation
relative √† l'IA en 2021. La tradition lib√©rale du pays se traduit par
une faible intervention de l'√âtat dans un domaine principalement domin√©
par des entreprises priv√©es.

La situation est diff√©rente en Chine, o√π le Parti communiste √† la t√™te
du gouvernement a clairement indiqu√© ses ambitions de d√©passer les
√©tats-Unis et de s'imposer dans le domaine de l'IA d'ici 2030. Pour ce
faire, elle adopte une attitude de laisser-faire et r√©gule en fonction
des situations et de ses int√©r√™ts. Un organe consacr√© √† l'administration
num√©rique est charg√© de ces questions. Des mesures sp√©cifiques visant √†
r√©guler l'application de l'IA dans divers services en ligne ont √©t√©
adopt√©es en mars 2022. Les acteurs concern√©s par ces r√©gulations sont
principalement des entreprises chinoises.

En Europe, la Commission europ√©enne a propos√© en avril 2021 ¬´ un
ensemble d'actions visant √† stimuler l'excellence dans le domaine de
l'IA, ainsi que des r√®gles destin√©es √† garantir la fiabilit√© de cette
technologie ¬ª[^1]. Afin d'estimer les risques que pourrait repr√©senter
l'IA pour les citoyens et citoyennes, la CE propose un classement qui
d√©termine le niveau de r√©gulation n√©cessaire pour chaque domaine. La
cat√©gorie ¬´ haut risque ¬ª comprend, par exemple, les logiciels de
recrutement ou les prises de d√©cision automatis√©es dans l'attribution
d'un cr√©dit, situations o√π les biais sont souvent pr√©sents. Les
ambitions de r√©gulation venant de la CE demeurent ambigu√´s puisqu'elle
ne dispose pas d'acteur majeur dans le domaine de l'IA.

```{admonition} Les enjeux de la conduite autonome
:class: hint

Le th√®me de la conduite autonome permet d'aborder diff√©rents enjeux
sociaux li√©s √† l'IA. L'automatisation du traitement des informations
contextuelles et des prises de d√©cision constitue un nouveau paradigme
de la conduite, qui touche directement √† des probl√©matiques techniques,
mais aussi aux questions de d√©l√©gation de certaines t√¢ches, de
responsabilit√© et de r√©gulation.

Comme les √™tres humains, les v√©hicules autonomes doivent apprendre √†
conduire afin d'√™tre capables d'effectuer des trajets de mani√®re s√ªre.
Pour ce faire, un important travail de programmation et d'entra√Ænement
est n√©cessaire. Les donn√©es contextuelles permettant aux v√©hicules de
s'orienter sont collect√©es gr√¢ce √† des capteurs (radars, lidars,
cam√©ras) puis trait√©es par un ordinateur embarqu√©. Ces dispositifs
doivent notamment permettre d'√©viter les obstacles, d'adapter la vitesse
et de respecter la signalisation.

Des robots-livreurs autonomes ont d√©j√† fait leurs preuves pour le
transport de nourriture ou de m√©dicaments, en Grande-Bretagne et en
Finlande. Il s'agit dans ce cas de petits v√©hicules qui se d√©placent √†
faible vitesse (6km/h), sur de courts trajets et en empruntant les voies
pi√©tonnes. L'utilisation de ces v√©hicules demeure marginale, mais
pourraient repr√©senter une s√©rieuse concurrence pour les m√©tiers de
coursier et de chauffeur.

L'autonomie des voitures, des bus ou encore des camions posent des d√©fis
plus exigeants. Il s'agit de v√©hicules plus imposants, visant √† √™tre
int√©gr√©s au trafic et pouvant transporter des personnes. Aussi, il est
techniquement plus complexe de garantir une conduite autonome s√ªre dans
un environnement o√π les param√®tres √† prendre en compte sont multiples et
parfois subjectifs.

La mise en circulation de tels v√©hicules requiert un cadre l√©gal adapt√©.
Il devra d√©terminer le type de v√©hicules autoris√©s sur les routes ainsi
que les mani√®res de r√©guler pr√©cis√©ment ces nouveaux acteurs. La
question de la responsabilit√© en cas d'accident demeure donc ouverte.

De mani√®re g√©n√©rale, la conduite autonome compl√®te n'est qu'√† ses
d√©buts. Les tests dans le trafic ont montr√© des r√©sultats mitig√©s et les
quelques accidents impliquant des voitures autonomes soulignent la
difficult√© de r√©soudre les probl√®mes de responsabilit√©.

On pr√©f√®re actuellement parler de conduite assist√©e, o√π la technologie
rend les trajets plus confortables, mais n'est pas encore en mesure de
remplacer l'√™tre humain dans toutes les situations.
```

## Ressources

* Le livre du physicien et sociologue Pablo Jensen, Pourquoi la soci√©t√© ne se laisse pas mettre en √©quation (2018)

* L‚Äôarticle (en anglais) sur la question de la r√©solution des biais

* Le reportage sur les biais sexistes dans les offres d‚Äôemploi en ligne, RTS

* Le podcast sur la question de l‚Äôintelligence en informatique. Le code a chang√©e, France Inter

* L‚Äôexposition ¬´ Intelligence artificielle, nos reflets dans la machine ¬ª au Mus√©e de la Main de Lausanne, jusqu‚Äôau 23 avril 2023

## Glossaire

* Biais

* Gouvernementalit√© algorithmique

* Luddites / luddisme

## Pistes p√©dagogiques

Pour des id√©es d'activit√©s sur cette th√©matique, voir le {download}`dossier<http://files.modulo-info.ch/enjeux-sociaux/ia-automatisation/IA-AutomatisationP2.pdf>`. 

<!-- Jeu de r√¥le¬†:

Objectifs¬†:

-   D√©couvrir les enjeux de la conduite autonome √† travers un jeu de
    r√¥le

-   Identifier les points de vue de diff√©rents acteurs

-   Construire un argumentaire coh√©rent √† l'aide de diff√©rents supports

üïì 45 min ‚úç d√©branch√©

Mat√©riel

5 fiches r√¥les

Article - Syndicat des transports publics

Tract - Groupe ¬´ Halte au progr√®s ¬ª

Pr√©sentation - Google Bus

Enqu√™te d'opinion - Service de la Mobilit√©

Principe

Pour cette activit√©, la classe met en sc√®ne un jeu de r√¥le autour du
th√®me de la conduite autonome. Chaque groupe endosse un r√¥le et pr√©pare
un argumentaire (pour ou contre l'acquisition d'une navette autonome par
la commune) afin de convaincre un jury.

Sc√©nario

Le Service de la Mobilit√© de la Ville souhaite innover en mati√®re de
transports publics et envisage un projet de navettes autonomes. Pour ce
faire, elle s'adresse au Conseil communal afin de pr√©senter et d√©fendre
ses arguments. Elle est soutenue par le constructeur des navettes Google
Bus, qui apporte son expertise technique.

Mais d'autres acteurs s'opposent au projet. Le groupe ¬´ halte au progr√®s
¬ª ainsi que le syndicat des transports publics vont √©galement prendre
position contre l'arriv√©e de navettes autonomes dans leur ville.

D√©roulement

1.  Former un premier groupe de quatre √† six √©l√®ves repr√©sentant les
    membres du conseil. Le reste des √©l√®ves endossent les autres r√¥les
    et forment **quatre groupes** d'au moins deux personnes.

2.  Distribuer les ¬´cartes r√¥le¬ª et le mat√©riel √† chaque groupe.

3.  Les √©l√®ves disposent de **15 minutes** pour prendre connaissance de
    leur r√¥le et pr√©parer un minimum de **3 arguments** pour d√©fendre
    leur position. Un porte-parole est d√©sign√© pour pr√©senter
    l'argumentaire au conseil.

4.  De leur c√¥t√©, les membres du conseil pr√©parent une question √† poser
    √† chaque groupe.

5.  Lorsque les 15 minutes sont √©coul√©es, les portes-paroles disposent
    de 3 minutes pour pr√©senter leurs arguments au conseil.

6.  Le conseil pose ensuite ses questions aux groupes qui disposent
    d'une minute pour r√©pondre.\
    \
    L'enseignant¬∑e s'assure que les temps de parole sont bien respect√©s,
    au moyen d'un chronom√®tre si n√©cessaire.

7.  Les √©changes termin√©s, les membres de jury votent pour ou contre le
    projet des navettes autonomes.

8.  L'enseignant¬∑e r√©colte les bulletins et annonce le verdict √† la
    classe.

Pr√©voir 5 minutes pour faire la **synth√®se** de l'activit√©. Demander aux
√©l√®ves s'ils/elles ont √©prouv√© des difficult√©s √† endosser leur r√¥le.
Pourquoi? Leur avis sur la conduite autonome a-t-il √©volu√©? -->

[^1]: https://ec.europa.eu/info/strategy/priorities-2019-2024/europe-fit-digital-age/excellence-trust-artificial-intelligence_fr\#stimuler-lexcellence-dans-le-domaine-de-lia,
consult√© le 31 mars 2022.
